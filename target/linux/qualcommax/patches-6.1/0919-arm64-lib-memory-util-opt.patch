arm64: lib: memory utilities optimization

Optimize memcpy and memmove, to prefetch several cache lines.
We can achieve 15% memcpy speed improvement with the preload method.

Signed-off-by: Hong-Mei Li <a21834@motorola.com>
Change-Id: Id93cb55b9c0c7344728ad57f585bf25fac3cd9d7
Reviewed-on: http://gerrit.mot.com/740766
SLTApproved: Slta Waiver <sltawvr@motorola.com>
SME-Granted: SME Approvals Granted
Tested-by: Jira Key <jirakey@motorola.com>
Reviewed-by: Zhi-Ming Yuan <a14194@motorola.com>
Submit-Approved: Jira Key <jirakey@motorola.com>

--- a/arch/arm64/lib/copy_template.S
+++ b/arch/arm64/lib/copy_template.S
@@ -39,6 +39,7 @@
 D_l	.req	x13
 D_h	.req	x14
 
+	prfm    pldl1strm, [src, #(1*L1_CACHE_BYTES)]
 	mov	dst, dstin
 	cmp	count, #16
 	/*When memory length is less than 16, the accessed are not aligned.*/
@@ -169,6 +170,7 @@
 	ldp1	C_l, C_h, src, #16
 	stp1	D_l, D_h, dst, #16
 	ldp1	D_l, D_h, src, #16
+	prfm    pldl1strm, [src, #(4*L1_CACHE_BYTES)]
 	subs	count, count, #64
 	b.ge	1b
 	stp1	A_l, A_h, dst, #16

